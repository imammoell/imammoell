# -*- coding: utf-8 -*-
"""OG linear regression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12y4S0IpR7qwkJbPmKVGQqiWRXSQXhV9N

DATA PREPERATION
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from matplotlib import pyplot as plt
import pandas as pd
from pandas.plotting import register_matplotlib_converters
register_matplotlib_converters()
import numpy as np
import seaborn as sn
import warnings
warnings.filterwarnings('ignore')
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima_model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression

df=pd.DataFrame()

df = pd.read_csv('/content/fix.csv')

df

df=df.drop(labels=1094, axis=0)

df=df.drop(["Unnamed: 2", "Unnamed: 3", "Unnamed: 4", "Unnamed: 5"], axis=1)

df

df['date'] = pd.to_datetime(df['Tanggal'])

df=df.drop(labels='Tanggal', axis=1)

df

df.shape

df.info()

import seaborn as sns

ax=sns.barplot(x=df['date'],y=df['Harga'],data=df)

df.describe()

"""FUTURE ENGIN

```
``
```

"""

reg_df = df

for i in range(1,8):
    lag_i = 'lag_' + str(i)
    reg_df[lag_i] = reg_df.Harga.shift(i)

reg_df['rolling_mean'] = reg_df.Harga.rolling(window=7).mean()
reg_df['rolling_max'] = reg_df.Harga.rolling(window=7).max()
reg_df['rolling_min'] = reg_df.Harga.rolling(window=7).min()

reg_df.info()

reg_df = reg_df.dropna(how='any', inplace=False)

reg_df

reg_train_df = reg_df.loc[:'2023-01-01']
reg_test_df = reg_df.loc['2023-01-02':]

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from matplotlib import pyplot as plt
from pandas.plotting import register_matplotlib_converters
register_matplotlib_converters()

###FEATURE SELECTION
corr = reg_train_df.corr()
fig = plt.figure(figsize=(10,7))
_ = sns.heatmap(corr, linewidths=.5)

X_train = reg_train_df.drop(['Harga'], axis=1)
y_train = reg_train_df['Harga'].values

X_test = reg_test_df.drop(['Harga'], axis=1)
y_test = reg_test_df['Harga'].values

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression

top_features = SelectKBest(score_func=f_regression, k=5)
fit = top_features.fit(X_train, y_train)
df_scores = pd.DataFrame(fit.scores_)
df_columns = pd.DataFrame(X_train.columns)

feature_scores = pd.concat([df_columns, df_scores], axis=1)
feature_scores.columns = ['Feature','Score']
print(feature_scores.nlargest(5,'Score'))

X_train = X_train[['lag_1', 'lag_2', 'rolling_mean', 'rolling_min', 'rolling_max']]
X_test = X_test[['lag_1', 'lag_2', 'rolling_mean', 'rolling_min', 'rolling_max']]

model = LinearRegression()
model.fit(X_train, y_train)

preds = model.predict(X_test)

errors_df = reg_test_df[['Harga']]
errors_df['pred_Harga'] = preds
errors_df['errors'] = preds - y_test
errors_df.insert(0, 'model', 'LinearRegression')

def mae(err):
    return np.mean(np.abs(err))

def rmse(err):
    return np.sqrt(np.mean(err ** 2))

def mape(err, sales=errors_df['Harga']):
    return np.sum(np.abs(err))/np.sum(sales) * 100

fig = plt.figure(figsize=(14,7))
plt.plot(errors_df.index, errors_df.errors, label='errors')
plt.plot(errors_df.index, errors_df.Harga, label='Harga asli')
plt.plot(errors_df.index, errors_df.pred_Harga, label='forecast')
plt.legend(loc='best')
plt.xlabel('date')
plt.ylabel('Harga')
plt.title('Linear Regression forecasts with Harga asli and errors')
plt.show()

result_df_lr = errors_df.groupby('model').agg(total_sales=('Harga', 'sum'),
                                          total_pred_sales=('pred_Harga', 'sum'),
                                          LR_overall_error=('errors', 'sum'),
                                          MAE=('errors', mae),
                                          RMSE=('errors', rmse),
                                          MAPE=('errors', mape))
result_df_lr

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from matplotlib import pyplot as plt
import pandas as pd
from pandas.plotting import register_matplotlib_converters
register_matplotlib_converters()
import numpy as np
import seaborn as sn
import warnings
warnings.filterwarnings('ignore')
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima_model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression

dates_2023 = pd.date_range(start='2023-11-26', end='2023-12-31', freq='D')

a={"date" : dates_2023, "Harga" : preds }
df_pred = pd.DataFrame.from_dict(a, orient='index')
df_pred = df_pred.transpose()

df_pred = df_pred.dropna()

df_pred

df_pred.to_csv('2023-11-26 sampai 2023-12-31.csv')

import joblib

joblib.dump(preds, 'regression_model.joblib')

from google.colab import files

files.download('regression_model.joblib')